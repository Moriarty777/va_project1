{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "AJ17p2rYlqo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import spacy\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "tZjQ0_4glmKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a9f9a0-5af3-4bc7-8a86-79b1d268837a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/data\"\n",
        "dir_list = os.listdir(path)\n",
        "os.chdir(\"/content/data\")\n",
        "\n",
        "universal_new_lines = '\\n' + '\\r' + '\\r\\n' + '\\v' + '\\x0b' + '\\f' + '\\x0c' + '\\x1c' + '\\x1d' + '\\x1e' + '\\x85' + '\\u2028' + '\\u2029' \n",
        "pun = string.punctuation + '\\t' + '—' + '‘’' + universal_new_lines\n",
        "label_list = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'LAW', 'DATE', 'TIME', 'MONEY']\n",
        "fields = ['VERB', 'PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'LAW', 'DATE', 'TIME', 'MONEY']\n",
        "processed_data = []"
      ],
      "metadata": {
        "id": "_73qjkbYqLTL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_processing(data):\n",
        "  # removing punctuations and new lines and tabs\n",
        "  for sym in pun:\n",
        "    cnt = data.count(sym)\n",
        "    data = data.replace(sym, '', cnt)\n",
        "\n",
        "  # lower the data\n",
        "  data = data.lower()\n",
        "  doc = nlp(data)\n",
        "\n",
        "  token_classification = {'VERB':[], 'PERSON':[], 'NORP':[], 'FAC':[], 'ORG':[], 'GPE':[], 'LOC':[], 'PRODUCT':[], 'EVENT':[], 'LAW':[], 'DATE':[], 'TIME':[], 'MONEY':[]}\n",
        "\n",
        "  # fetching entities and keywords\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ in label_list:\n",
        "      if ent.text not in token_classification[ent.label_]:\n",
        "        token_classification[ent.label_].append(ent.text)\n",
        "  \n",
        "  for token in doc:\n",
        "    if token.pos_ == 'VERB':\n",
        "      if token.lemma_ not in token_classification['VERB']:\n",
        "        token_classification['VERB'].append(token.lemma_)\n",
        "\n",
        "  return token_classification"
      ],
      "metadata": {
        "id": "H_JKWZw1ooxc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in dir_list:\n",
        "  file = open(fname)\n",
        "  content_list = file.readlines()\n",
        "  while '\\n' in content_list:\n",
        "    content_list.remove('\\n')\n",
        "  for content in content_list:\n",
        "    token_classification = data_processing(content)\n",
        "    processed_data.append(token_classification)\n",
        "# print(processed_data)\n",
        "\n",
        "with open(\"/content/ProcessedData.csv\", 'w') as csvfile:\n",
        "  writer = csv.DictWriter(csvfile, fieldnames = fields)\n",
        "  writer.writeheader()\n",
        "  writer.writerows(processed_data)"
      ],
      "metadata": {
        "id": "MyNQyzU8l81I"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}